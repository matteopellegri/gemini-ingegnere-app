{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMrTlz1FaJdHleLZ+Iz8n0J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BMmeXGrVjPG6"},"outputs":[],"source":["# Importa le librerie necessarie per Streamlit e Gemini\n","import streamlit as st\n","import google.generativeai as genai\n","import os # Per gestire le variabili d'ambiente (API Key)\n","import matplotlib.pyplot as plt # Per i grafici\n","import numpy as np # Per i dati dei grafici\n","\n","# --- Configurazione della Chiave API ---\n","# In un'applicazione Streamlit in deploy, la chiave API viene gestita\n","# in modo sicuro tramite le \"Secrets\" o le variabili d'ambiente della piattaforma di hosting.\n","# Per test locali, potresti doverla impostare manualmente o tramite un file .env.\n","# Per il deploy su Streamlit Cloud, useremo st.secrets.\n","# Per altre piattaforme, useremo os.getenv.\n","try:\n","    API_KEY = os.getenv('GEMINI_API_KEY')\n","    if not API_KEY:\n","        # Se non √® impostata come variabile d'ambiente (es. per test locale senza .env)\n","        # potresti volerla chiedere o impostarla direttamente qui, ma ATTENZIONE ALLA SICUREZZA!\n","        # Per semplicit√†, qui simuliamo un errore se non √® trovata.\n","        st.error(\"Errore: La chiave API 'GEMINI_API_KEY' non √® configurata come variabile d'ambiente o secret.\")\n","        st.info(\"Assicurati di impostare la variabile d'ambiente 'GEMINI_API_KEY' o il secret sulla piattaforma di deploy.\")\n","        st.stop() # Ferma l'esecuzione dell'app Streamlit\n","except Exception as e:\n","    st.error(f\"Errore durante il recupero della chiave API: {e}\")\n","    st.stop()\n","\n","# Configura la libreria Gemini con la chiave API\n","genai.configure(api_key=API_KEY)\n","\n","# --- Verifica e Selezione del Modello Gemini ---\n","# Questa logica √® fondamentale per assicurarsi di usare un modello disponibile.\n","MODEL_NAME = None\n","try:\n","    available_models = [m for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n","    if available_models:\n","        preferred_models = ['gemini-2.0-flash', 'gemini-1.5-pro', 'gemini-1.0-pro', 'gemini-pro']\n","        for pref_model in preferred_models:\n","            if any(pref_model in m.name for m in available_models):\n","                MODEL_NAME = pref_model\n","                break\n","\n","        if MODEL_NAME is None:\n","            MODEL_NAME = available_models[0].name # Prendi il primo disponibile\n","            st.warning(f\"Attenzione: Nessun modello preferito trovato. Utilizzando il modello: {MODEL_NAME}\")\n","    else:\n","        st.error(\"Nessun modello Gemini trovato che supporta 'generateContent'. Prover√≤ con 'gemini-2.0-flash' come fallback.\")\n","        MODEL_NAME = 'gemini-2.0-flash'\n","except Exception as e:\n","    st.error(f\"Errore durante la ricerca dei modelli disponibili: {e}. Prover√≤ con 'gemini-2.0-flash' come fallback.\")\n","    MODEL_NAME = 'gemini-2.0-flash'\n","\n","try:\n","    model = genai.GenerativeModel(MODEL_NAME)\n","    st.success(f\"Modello Gemini selezionato: {MODEL_NAME}\")\n","except Exception as e:\n","    st.error(f\"Errore critico: Impossibile caricare il modello '{MODEL_NAME}'. Errore: {e}\")\n","    st.info(\"Assicurati che la tua chiave API sia corretta e che il modello sia disponibile per il tuo progetto.\")\n","    st.stop() # Ferma l'esecuzione dell'app se il modello non carica\n","\n","\n","# --- Funzione per Generare un Report Concettuale (Integrata) ---\n","def generate_engineering_report(title: str, query: str):\n","    \"\"\"\n","    Genera un report di ingegneria concettuale per la web app.\n","    Ritorna il contenuto Markdown del report e salva un'immagine del grafico.\n","    \"\"\"\n","    report_content = f\"# {title}\\n\\n\"\n","    report_content += \"## Indice\\n\"\n","    report_content += \"- [Introduzione](#introduzione)\\n\"\n","    report_content += \"- [Analisi del Problema](#analisi-problema)\\n\"\n","    report_content += \"- [Risultati e Calcoli](#risultati-calcoli)\\n\"\n","    report_content += \"- [Rappresentazione Grafica](#rappresentazione-grafica)\\n\"\n","    report_content += \"- [Conclusioni e Disclaimer](#conclusioni-disclaimer)\\n\\n\"\n","\n","    report_content += \"## Introduzione\\n\"\n","    report_content += f\"Questo report √® generato in risposta alla tua richiesta: '{query}'.\\n\"\n","    report_content += \"Si propone di fornire un'analisi preliminare e alcuni calcoli pertinenti al problema.\\n\\n\"\n","\n","    try:\n","        with st.spinner(\"L'Agente sta preparando l'analisi del problema...\"):\n","            analysis_prompt = f\"Genera una breve analisi tecnica sul seguente problema di ingegneria civile/edile, tenendo conto del ruolo di un assistente AI ingegneristico. Problema: '{query}'. Includi aspetti chiave e considerazioni preliminari.\"\n","            analysis_response = model.generate_content(analysis_prompt)\n","            report_content += \"## Analisi del Problema\\n\"\n","            report_content += analysis_response.text + \"\\n\\n\"\n","    except Exception as e:\n","        report_content += f\"## Analisi del Problema\\nErrore durante la generazione dell'analisi da parte di Gemini: {e}\\n\\n\"\n","\n","    # Simulazione di calcolo\n","    force = 100 # kN\n","    area = 0.25 # m^2 (es. colonna 50x50cm)\n","    stress = force / area # kN/m^2 = kPa\n","    report_content += \"## Risultati e Calcoli Preliminari\\n\"\n","    report_content += \"Simulazione di calcolo di esempio (Sforzo Normale):\\n\"\n","    report_content += f\"Formula: Sforzo ($ \\sigma $) = Forza (F) / Area (A)\\n\"\n","    report_content += f\"Valori: F = {force} kN, A = {area} m$^2$\\n\"\n","    report_content += f\"Calcolo: $\\sigma$ = {force} kN / {area} m$^2$ = {stress} kPa\\n\\n\"\n","\n","    # --- Generazione di un Grafico (Matplotlib) ---\n","    with st.spinner(\"L'Agente sta generando un grafico per il report...\"):\n","        fig, ax = plt.subplots(figsize=(8, 5))\n","        x = np.linspace(0, 10, 100)\n","        y = x**2 + np.random.rand(100) * 10\n","        ax.plot(x, y, label='Esempio di Dati')\n","        ax.set_title('Grafico di Esempio per il Report')\n","        ax.set_xlabel('Asse X (Unit√†)')\n","        ax.set_ylabel('Asse Y (Unit√†)')\n","        ax.grid(True)\n","        ax.legend()\n","\n","        # Streamlit pu√≤ mostrare la figura direttamente\n","        st.pyplot(fig)\n","        plt.close(fig) # Chiudi la figura per liberare memoria\n","\n","    report_content += \"## Rappresentazione Grafica\\n\"\n","    report_content += \"Il grafico sopra illustra i dati relativi all'analisi.\\n\\n\"\n","\n","\n","    report_content += \"## Conclusioni e Disclaimer\\n\"\n","    report_content += \"Questo report √® un'analisi preliminare generata da un assistente AI. I calcoli e le informazioni fornite sono a scopo puramente indicativo e non devono essere utilizzati per la progettazione o la valutazione strutturale reale.\\n\"\n","    report_content += \"**ATTENZIONE: Questo calcolo √® puramente indicativo e non sostituisce il calcolo professionale di un ingegnere qualificato. Verifica sempre i risultati con software specialistici e normative vigenti.**\\n\\n\"\n","    report_content += \"--- Fine del Report ---\"\n","\n","    return report_content\n","\n","# --- Interfaccia Utente della Web App Streamlit ---\n","\n","st.title(\"üë®‚Äçüíª Agente AI per Ingegneria Edile/Civile\")\n","st.markdown(\"Sono un assistente AI specializzato in ingegneria. Posso rispondere a domande, eseguire calcoli preliminari e generare report concettuali.\")\n","st.write(f\"*(Modello Gemini utilizzato: {MODEL_NAME})*\")\n","\n","# Inizializzazione della sessione di chat di Gemini con il prompt dell'agente\n","# Usiamo st.session_state per mantenere la cronologia della chat tra le interazioni utente\n","if \"chat_session\" not in st.session_state:\n","    st.session_state.chat_session = model.start_chat(history=[\n","        {\n","            \"role\": \"user\",\n","            \"parts\": [\n","                \"Sei un assistente AI specializzato in Ingegneria Edile e Civile, con particolare competenza in Scienza delle Costruzioni, calcolo strutturale, meccanica dei materiali, propriet√† dei materiali da costruzione (calcestruzzo, acciaio, legno), elementi di geotecnica e idraulica, e principi delle normative tecniche italiane ed europee (generale, non specifico dettaglio normativo).\",\n","                \"Il tuo obiettivo √® fornire risposte accurate, chiare, concise e tecnicamente corrette. Quando esegui calcoli, segui questi passaggi rigorosi:\",\n","                \"1. Mostra la formula completa che intendi utilizzare (anche se la scrivi in formato testo per chiarezza).\",\n","                \"2. Elenca tutti i valori e le unit√† di misura che stai utilizzando per ciascuna variabile della formula.\",\n","                \"3. Mostra i passaggi del calcolo in modo leggibile.\",\n","                \"4. Fornisci il risultato finale con l'unit√† di misura appropriata.\",\n","                \"5. Aggiungi sempre un **disclaimer importante**: 'ATTENZIONE: Questo calcolo √® puramente indicativo e non sostituisce il calcolo professionale di un ingegnere qualificato. Verifica sempre i risultati con software specialistici e normative vigenti.'\",\n","                \"Se non conosci la risposta, o se una domanda √® troppo complessa, ambigua, richiede dati esterni non forniti o rientra in ambito di progettazione critica non adatta a un LLM, dichiara chiaramente la tua limitazione e suggerisci all'utente di consultare un esperto o un software dedicato.\",\n","                \"Utilizza sempre la terminologia tecnica appropriata. Non devi inventare dati o presupposti non esplicitamente forniti.\",\n","                \"Se l'utente chiede un 'report' o una 'relazione di calcolo', prova a generare un report strutturato che includa introduzione, analisi, risultati, grafici e conclusioni, sempre con il disclaimer.\"\n","            ]\n","        },\n","        {\"role\": \"model\", \"parts\": [\"Comprendo il mio ruolo. Sono pronto ad assisterti con domande, calcoli preliminari e la generazione di report concettuali nel campo dell'Ingegneria Edile e Civile. Ricorda sempre l'importanza della verifica professionale dei risultati. Come posso aiutarti oggi?\"]}\n","    ])\n","\n","# Mostra la cronologia della chat\n","for message in st.session_state.chat_session.history:\n","    with st.chat_message(message.role):\n","        st.markdown(message.parts[0].text)\n","\n","# Campo di input per l'utente\n","user_input = st.chat_input(\"Digita la tua richiesta qui... (es: 'Spiegami la legge di Hooke' o 'Genera un report sui carichi dinamici')\")\n","\n","if user_input:\n","    # Mostra il messaggio dell'utente nella chat\n","    st.chat_message(\"user\").markdown(user_input)\n","\n","    # Rileva la richiesta di un report\n","    if \"genera un report su\" in user_input.lower() or \"crea una relazione di calcolo per\" in user_input.lower():\n","        report_topic = user_input.replace(\"genera un report su\", \"\").replace(\"crea una relazione di calcolo per\", \"\").strip()\n","        if not report_topic:\n","            report_topic = \"un argomento generico di ingegneria\"\n","\n","        with st.chat_message(\"assistant\"):\n","            st.write(f\"Ok, sto preparando un report su '{report_topic}'. Questo potrebbe richiedere un momento.\")\n","            generated_report = generate_engineering_report(f\"Relazione Tecnica Preliminare su {report_topic}\", user_input)\n","            st.markdown(\"---\")\n","            st.markdown(\"### Report Generato\")\n","            st.markdown(generated_report)\n","            st.markdown(\"---\")\n","            st.info(\"Nota: Questo report √® un'analisi preliminare. L'immagine del grafico √® incorporata direttamente. C'√® qualcos'altro in cui posso aiutarti?\")\n","    else:\n","        # Invia il messaggio a Gemini per una normale conversazione\n","        try:\n","            with st.spinner(\"L'Agente sta pensando...\"):\n","                response = st.session_state.chat_session.send_message(user_input)\n","                with st.chat_message(\"assistant\"):\n","                    st.markdown(response.text)\n","        except Exception as e:\n","            with st.chat_message(\"assistant\"):\n","                st.error(f\"Si √® verificato un errore nella comunicazione con l'Agente: {e}\")\n","                st.info(\"Potrebbe esserci un problema di rete o una richiesta troppo complessa. Riprova.\")\n","\n"]}]}